<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Quiz ‚Äî Chapter 1: Understanding Large Language Models</title>
<link href="https://fonts.googleapis.com/css2?family=DM+Sans:wght@400;500;700&family=Libre+Baskerville:wght@400;700&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
<style>
  :root {
    --bg: #f5f0e8;
    --surface: #ffffff;
    --text: #2a2520;
    --muted: #7a7268;
    --accent: #3a5bc7;
    --correct: #2a7a44;
    --correct-bg: #edf7f0;
    --wrong: #c44830;
    --wrong-bg: #fdf0ed;
    --warn: #a07818;
    --warn-bg: #fdf8ed;
    --border: #e0d8c8;
    --radius: 10px;
  }

  * { margin: 0; padding: 0; box-sizing: border-box; }

  body {
    font-family: 'DM Sans', sans-serif;
    background: var(--bg);
    color: var(--text);
    line-height: 1.65;
    min-height: 100vh;
  }

  .container {
    max-width: 740px;
    margin: 0 auto;
    padding: 40px 24px 80px;
  }

  /* ‚îÄ‚îÄ Header ‚îÄ‚îÄ */
  .header {
    text-align: center;
    margin-bottom: 48px;
    animation: fadeDown .6s ease;
  }
  .header-icon {
    font-size: 3rem;
    margin-bottom: 8px;
  }
  .header h1 {
    font-family: 'Libre Baskerville', serif;
    font-size: 1.9rem;
    font-weight: 700;
    margin-bottom: 6px;
    letter-spacing: -0.02em;
  }
  .header p {
    color: var(--muted);
    font-size: 1.05rem;
  }

  /* ‚îÄ‚îÄ Progress Bar ‚îÄ‚îÄ */
  .progress-wrap {
    position: sticky;
    top: 0;
    z-index: 100;
    background: var(--bg);
    padding: 12px 0 8px;
    margin-bottom: 24px;
  }
  .progress-bar-outer {
    height: 6px;
    background: var(--border);
    border-radius: 3px;
    overflow: hidden;
  }
  .progress-bar-inner {
    height: 100%;
    background: var(--accent);
    border-radius: 3px;
    width: 0%;
    transition: width .4s ease;
  }
  .progress-text {
    text-align: right;
    font-size: .82rem;
    color: var(--muted);
    margin-top: 4px;
  }

  /* ‚îÄ‚îÄ Question Card ‚îÄ‚îÄ */
  .question-card {
    background: var(--surface);
    border: 1px solid var(--border);
    border-radius: var(--radius);
    padding: 28px 28px 24px;
    margin-bottom: 20px;
    opacity: 0;
    transform: translateY(16px);
    animation: fadeUp .5s ease forwards;
  }
  .question-card:nth-child(1) { animation-delay: .05s; }
  .question-card:nth-child(2) { animation-delay: .1s; }
  .question-card:nth-child(3) { animation-delay: .15s; }
  .question-card:nth-child(4) { animation-delay: .2s; }
  .question-card:nth-child(5) { animation-delay: .25s; }
  .question-card:nth-child(6) { animation-delay: .3s; }
  .question-card:nth-child(7) { animation-delay: .35s; }
  .question-card:nth-child(8) { animation-delay: .4s; }
  .question-card:nth-child(9) { animation-delay: .45s; }
  .question-card:nth-child(10) { animation-delay: .5s; }

  .q-number {
    font-family: 'JetBrains Mono', monospace;
    font-size: .78rem;
    font-weight: 500;
    color: var(--accent);
    text-transform: uppercase;
    letter-spacing: .08em;
    margin-bottom: 8px;
  }
  .q-text {
    font-family: 'Libre Baskerville', serif;
    font-size: 1.08rem;
    font-weight: 400;
    line-height: 1.6;
    margin-bottom: 18px;
  }

  /* ‚îÄ‚îÄ Options ‚îÄ‚îÄ */
  .options { display: flex; flex-direction: column; gap: 8px; }
  .option-btn {
    display: flex;
    align-items: flex-start;
    gap: 12px;
    padding: 14px 16px;
    border: 1.5px solid var(--border);
    border-radius: 8px;
    background: transparent;
    cursor: pointer;
    text-align: left;
    font-family: 'DM Sans', sans-serif;
    font-size: .95rem;
    color: var(--text);
    line-height: 1.5;
    transition: all .2s ease;
    width: 100%;
  }
  .option-btn:hover:not(.disabled) {
    border-color: var(--accent);
    background: #f0f2fa;
  }
  .option-btn.selected {
    border-color: var(--accent);
    background: #ebeefa;
    font-weight: 500;
  }
  .option-btn.disabled { cursor: default; opacity: .95; }
  .option-btn.correct-answer {
    border-color: var(--correct);
    background: var(--correct-bg);
  }
  .option-btn.wrong-answer {
    border-color: var(--wrong);
    background: var(--wrong-bg);
  }

  .option-letter {
    flex-shrink: 0;
    width: 28px;
    height: 28px;
    border-radius: 50%;
    background: var(--bg);
    display: flex;
    align-items: center;
    justify-content: center;
    font-family: 'JetBrains Mono', monospace;
    font-size: .8rem;
    font-weight: 500;
    color: var(--muted);
    margin-top: 1px;
    transition: all .2s;
  }
  .option-btn.selected .option-letter {
    background: var(--accent);
    color: #fff;
  }
  .option-btn.correct-answer .option-letter {
    background: var(--correct);
    color: #fff;
  }
  .option-btn.wrong-answer .option-letter {
    background: var(--wrong);
    color: #fff;
  }

  /* ‚îÄ‚îÄ Feedback ‚îÄ‚îÄ */
  .feedback {
    margin-top: 14px;
    padding: 14px 16px;
    border-radius: 8px;
    font-size: .9rem;
    line-height: 1.6;
    display: none;
  }
  .feedback.show { display: block; animation: fadeUp .3s ease; }
  .feedback.correct { background: var(--correct-bg); color: #1d5a30; border-left: 3px solid var(--correct); }
  .feedback.wrong { background: var(--wrong-bg); color: #8a2c1a; border-left: 3px solid var(--wrong); }
  .feedback.skipped { background: var(--warn-bg); color: #6a5010; border-left: 3px solid var(--warn); }
  .feedback strong { font-weight: 700; }

  /* ‚îÄ‚îÄ Submit Area ‚îÄ‚îÄ */
  .submit-area {
    text-align: center;
    margin-top: 32px;
  }
  .btn-primary {
    display: inline-flex;
    align-items: center;
    gap: 8px;
    padding: 16px 48px;
    font-family: 'DM Sans', sans-serif;
    font-size: 1.05rem;
    font-weight: 700;
    color: #fff;
    background: var(--accent);
    border: none;
    border-radius: 50px;
    cursor: pointer;
    transition: all .2s;
    box-shadow: 0 4px 16px rgba(58, 91, 199, .25);
  }
  .btn-primary:hover { transform: translateY(-2px); box-shadow: 0 6px 24px rgba(58, 91, 199, .35); }
  .btn-primary:active { transform: translateY(0); }
  .btn-primary:disabled { opacity: .5; cursor: not-allowed; transform: none; box-shadow: none; }

  .btn-secondary {
    display: inline-flex;
    align-items: center;
    gap: 8px;
    padding: 14px 40px;
    font-family: 'DM Sans', sans-serif;
    font-size: 1rem;
    font-weight: 600;
    color: var(--accent);
    background: transparent;
    border: 2px solid var(--accent);
    border-radius: 50px;
    cursor: pointer;
    transition: all .2s;
    margin-top: 16px;
  }
  .btn-secondary:hover { background: var(--accent); color: #fff; }

  .answered-count {
    color: var(--muted);
    font-size: .9rem;
    margin-bottom: 12px;
  }

  /* ‚îÄ‚îÄ Score Card ‚îÄ‚îÄ */
  .score-card {
    text-align: center;
    padding: 40px 32px;
    background: var(--surface);
    border: 1px solid var(--border);
    border-radius: var(--radius);
    margin-bottom: 32px;
    animation: fadeUp .5s ease;
  }
  .score-emoji { font-size: 3.2rem; margin-bottom: 8px; }
  .score-number {
    font-family: 'Libre Baskerville', serif;
    font-size: 2.8rem;
    font-weight: 700;
  }
  .score-pct {
    font-size: 1.1rem;
    color: var(--muted);
    margin: 4px 0 12px;
  }
  .score-msg {
    font-size: 1.05rem;
    font-weight: 500;
  }
  .score-card.excellent .score-number { color: var(--correct); }
  .score-card.good .score-number { color: var(--warn); }
  .score-card.retry .score-number { color: var(--wrong); }

  /* ‚îÄ‚îÄ Summary chips ‚îÄ‚îÄ */
  .summary-row {
    display: flex;
    flex-wrap: wrap;
    gap: 8px;
    justify-content: center;
    margin-bottom: 24px;
  }
  .summary-chip {
    display: inline-flex;
    align-items: center;
    gap: 4px;
    padding: 6px 14px;
    border-radius: 20px;
    font-size: .85rem;
    font-weight: 500;
  }
  .summary-chip.c { background: var(--correct-bg); color: var(--correct); }
  .summary-chip.w { background: var(--wrong-bg); color: var(--wrong); }
  .summary-chip.s { background: var(--warn-bg); color: var(--warn); }

  /* ‚îÄ‚îÄ Animations ‚îÄ‚îÄ */
  @keyframes fadeUp {
    from { opacity: 0; transform: translateY(16px); }
    to   { opacity: 1; transform: translateY(0); }
  }
  @keyframes fadeDown {
    from { opacity: 0; transform: translateY(-16px); }
    to   { opacity: 1; transform: translateY(0); }
  }

  /* ‚îÄ‚îÄ Mobile ‚îÄ‚îÄ */
  @media (max-width: 600px) {
    .container { padding: 24px 16px 60px; }
    .header h1 { font-size: 1.5rem; }
    .question-card { padding: 20px 18px 18px; }
    .q-text { font-size: 1rem; }
    .option-btn { padding: 12px 14px; font-size: .9rem; }
    .score-number { font-size: 2.2rem; }
  }
</style>
</head>
<body>
<div class="container">

  <!-- Header -->
  <div class="header">
    <div class="header-icon">üìù</div>
    <h1>Chapter 1 Quiz</h1>
    <p>Understanding Large Language Models ‚Äî 10 Questions</p>
  </div>

  <!-- Progress -->
  <div class="progress-wrap">
    <div class="progress-bar-outer">
      <div class="progress-bar-inner" id="progressBar"></div>
    </div>
    <div class="progress-text" id="progressText">0 / 10 answered</div>
  </div>

  <!-- Questions -->
  <div id="questionsContainer"></div>

  <!-- Submit -->
  <div class="submit-area" id="submitArea">
    <div class="answered-count" id="answeredCount"></div>
    <button class="btn-primary" id="submitBtn" onclick="submitQuiz()" disabled>
      üìä Submit Quiz
    </button>
  </div>

  <!-- Score (hidden until submit) -->
  <div id="scoreArea" style="display:none;"></div>

</div>

<script>
// ============================================================
// QUIZ DATA
// ============================================================
const QUESTIONS = [
  {
    q: "According to the hierarchy in Figure 1.1, what is the correct nesting order from broadest to most specific?",
    options: [
      "Deep learning ‚Üí Machine learning ‚Üí AI ‚Üí LLMs",
      "AI ‚Üí Machine learning ‚Üí Deep learning ‚Üí LLMs",
      "Machine learning ‚Üí AI ‚Üí Deep learning ‚Üí GenAI",
      "LLMs ‚Üí Deep learning ‚Üí Machine learning ‚Üí AI"
    ],
    answer: 1,
    explain: "AI is the broadest field (systems with human-like intelligence). Machine learning is a subset of AI (algorithms that learn from data). Deep learning is a subset of ML (multi-layer neural networks). LLMs are a specific application of deep learning for processing and generating text."
  },
  {
    q: "What is the key difference between machine learning and traditional programming?",
    options: [
      "Machine learning runs faster than traditional programs",
      "Machine learning algorithms learn rules from data rather than being explicitly programmed",
      "Traditional programming cannot handle text data",
      "Machine learning requires less data than traditional programming"
    ],
    answer: 1,
    explain: "The chapter uses a spam filter example: instead of manually writing rules to identify spam, a machine learning algorithm is fed examples of spam and non-spam emails and learns to identify patterns on its own."
  },
  {
    q: "The original transformer architecture (2017) consists of which two main components?",
    options: [
      "A generator and a discriminator",
      "An encoder and a decoder",
      "A tokenizer and an embedder",
      "A convolutional layer and a recurrent layer"
    ],
    answer: 1,
    explain: "As shown in Figure 1.4, the original transformer has an encoder (which processes the input text and produces embedding representations) and a decoder (which generates the output text one word at a time). It was originally designed for language translation."
  },
  {
    q: "BERT and GPT each use different parts of the transformer. Which statement is correct?",
    options: [
      "BERT uses the decoder; GPT uses the encoder",
      "Both BERT and GPT use the full encoder-decoder architecture",
      "BERT uses the encoder (masked word prediction); GPT uses the decoder (next-word generation)",
      "BERT uses neither ‚Äî it is a completely new architecture"
    ],
    answer: 2,
    explain: "As illustrated in Figure 1.5, BERT is encoder-based ‚Äî it receives inputs where words are randomly masked and learns to fill in the missing words. GPT is decoder-based ‚Äî it receives incomplete texts and learns to generate the next word, one at a time."
  },
  {
    q: "What is the pretraining task used to train GPT-style models?",
    options: [
      "Image classification on labeled datasets",
      "Translating sentences between languages",
      "Next-word prediction on large unlabeled text corpora",
      "Answering multiple-choice questions from exams"
    ],
    answer: 2,
    explain: "GPT models are pretrained using next-word prediction ‚Äî the model learns to predict the upcoming word in a sentence given the words that came before it. This is a form of self-supervised learning because the labels come from the structure of the data itself."
  },
  {
    q: "Why is next-word prediction considered 'self-supervised' learning?",
    options: [
      "Because the model supervises other models during training",
      "Because humans must manually label every training example",
      "Because the labels are generated from the data itself ‚Äî the next word serves as the target",
      "Because the model does not require any data to learn"
    ],
    answer: 2,
    explain: "Self-supervised learning means the training labels are derived from the structure of the data, not from human annotators. In next-word prediction, the next word in the text is the label, so massive unlabeled text datasets can be used for training."
  },
  {
    q: "What does it mean that GPT models are 'autoregressive'?",
    options: [
      "They process all words in a sentence simultaneously",
      "They generate text by incorporating their previous outputs as inputs for future predictions",
      "They can only process numerical data, not text",
      "They require the full output to be specified in advance"
    ],
    answer: 1,
    explain: "As shown in Figure 1.8, autoregressive generation means the model produces one word at a time, and each new word is chosen based on the entire sequence that precedes it (including previously generated words). The output of each round becomes part of the input for the next."
  },
  {
    q: "What is the difference between 'zero-shot' and 'few-shot' settings for LLMs?",
    options: [
      "Zero-shot uses the full training set; few-shot uses a small training set",
      "Zero-shot means the model performs a task without any examples in the input; few-shot provides a few examples within the input",
      "Zero-shot is faster; few-shot is more accurate but slower",
      "They are the same thing with different names"
    ],
    answer: 1,
    explain: "As illustrated in Figure 1.6, in a zero-shot setting the model performs a task (like translation) without any explicit examples ‚Äî just an instruction. In a few-shot setting, a few examples of the task are provided in the input (e.g., 'gaot => goat, sheo => shoe, pohne => ?') to help the model understand the pattern."
  },
  {
    q: "What is the relationship between pretraining and fine-tuning in LLM development?",
    options: [
      "Pretraining and fine-tuning are the same process",
      "Pretraining uses a large unlabeled corpus to build a foundation model; fine-tuning then specializes it on a smaller labeled dataset for specific tasks",
      "Fine-tuning always happens before pretraining",
      "Pretraining requires labeled data; fine-tuning uses unlabeled data"
    ],
    answer: 1,
    explain: "As depicted in Figure 1.3, an LLM is first pretrained on massive unlabeled text data (internet text, books, Wikipedia) to learn general language understanding. This pretrained foundation model can then be fine-tuned on a smaller labeled dataset for specific tasks like classification, summarization, or translation."
  },
  {
    q: "How does GPT-3 compare to the original transformer in terms of scale?",
    options: [
      "They are roughly the same size",
      "GPT-3 is smaller but more efficient",
      "GPT-3 has 96 transformer layers and 175 billion parameters ‚Äî far larger than the original which repeated its blocks only 6 times",
      "The original transformer has more parameters because it includes both encoder and decoder"
    ],
    answer: 2,
    explain: "The original transformer repeated the encoder and decoder blocks six times. GPT-3, by contrast, has 96 transformer layers and 175 billion parameters in total ‚Äî a massive scale-up that is a key reason for its impressive capabilities."
  }
];

// ============================================================
// STATE
// ============================================================
let answers = new Array(QUESTIONS.length).fill(null);
let submitted = false;

// ============================================================
// RENDER QUESTIONS
// ============================================================
function renderQuestions() {
  const container = document.getElementById('questionsContainer');
  container.innerHTML = '';

  QUESTIONS.forEach((qdata, i) => {
    const card = document.createElement('div');
    card.className = 'question-card';
    card.id = `card-${i}`;

    const letters = ['A', 'B', 'C', 'D'];

    card.innerHTML = `
      <div class="q-number">Question ${i + 1} of ${QUESTIONS.length}</div>
      <div class="q-text">${qdata.q}</div>
      <div class="options" id="options-${i}">
        ${qdata.options.map((opt, j) => `
          <button class="option-btn" id="opt-${i}-${j}" onclick="selectOption(${i}, ${j})">
            <span class="option-letter">${letters[j]}</span>
            <span>${opt}</span>
          </button>
        `).join('')}
      </div>
      <div class="feedback" id="feedback-${i}"></div>
    `;

    container.appendChild(card);
  });
}

// ============================================================
// SELECT OPTION
// ============================================================
function selectOption(qIndex, optIndex) {
  if (submitted) return;

  answers[qIndex] = optIndex;

  // Update option styles
  const options = document.querySelectorAll(`#options-${qIndex} .option-btn`);
  options.forEach((btn, j) => {
    btn.classList.remove('selected');
    if (j === optIndex) btn.classList.add('selected');
  });

  updateProgress();
}

// ============================================================
// UPDATE PROGRESS
// ============================================================
function updateProgress() {
  const answered = answers.filter(a => a !== null).length;
  const total = QUESTIONS.length;
  const pct = (answered / total) * 100;

  document.getElementById('progressBar').style.width = pct + '%';
  document.getElementById('progressText').textContent = `${answered} / ${total} answered`;
  document.getElementById('answeredCount').textContent = `${answered} of ${total} questions answered`;
  document.getElementById('submitBtn').disabled = answered === 0;
}

// ============================================================
// SUBMIT QUIZ
// ============================================================
function submitQuiz() {
  if (submitted) return;
  submitted = true;

  let score = 0;

  QUESTIONS.forEach((qdata, i) => {
    const options = document.querySelectorAll(`#options-${i} .option-btn`);
    const feedback = document.getElementById(`feedback-${i}`);

    // Disable all buttons
    options.forEach(btn => btn.classList.add('disabled'));

    if (answers[i] === null) {
      // Not answered
      options[qdata.answer].classList.add('correct-answer');
      feedback.className = 'feedback skipped show';
      feedback.innerHTML = `<strong>‚ö†Ô∏è Not answered.</strong> The correct answer was <strong>${['A','B','C','D'][qdata.answer]}</strong>.<br>${qdata.explain}`;
    } else if (answers[i] === qdata.answer) {
      // Correct
      score++;
      options[answers[i]].classList.add('correct-answer');
      feedback.className = 'feedback correct show';
      feedback.innerHTML = `<strong>‚úÖ Correct!</strong> ${qdata.explain}`;
    } else {
      // Wrong
      options[answers[i]].classList.add('wrong-answer');
      options[qdata.answer].classList.add('correct-answer');
      feedback.className = 'feedback wrong show';
      feedback.innerHTML = `<strong>‚ùå Incorrect.</strong> The correct answer was <strong>${['A','B','C','D'][qdata.answer]}</strong>.<br>${qdata.explain}`;
    }
  });

  // Hide submit, show score
  document.getElementById('submitArea').style.display = 'none';
  showScore(score);

  // Scroll to top
  window.scrollTo({ top: 0, behavior: 'smooth' });
}

// ============================================================
// SHOW SCORE
// ============================================================
function showScore(score) {
  const total = QUESTIONS.length;
  const pct = Math.round((score / total) * 100);

  let emoji, msg, cls;
  if (pct >= 80) {
    emoji = 'üéâ'; msg = 'Excellent work!'; cls = 'excellent';
  } else if (pct >= 60) {
    emoji = 'üëç'; msg = 'Good effort ‚Äî review the ones you missed.'; cls = 'good';
  } else {
    emoji = 'üìñ'; msg = 'Consider re-reading the chapter and trying again.'; cls = 'retry';
  }

  // Build summary chips
  let chips = '';
  QUESTIONS.forEach((qdata, i) => {
    if (answers[i] === null) {
      chips += `<span class="summary-chip s">Q${i+1} ‚ö†Ô∏è</span>`;
    } else if (answers[i] === qdata.answer) {
      chips += `<span class="summary-chip c">Q${i+1} ‚úì</span>`;
    } else {
      chips += `<span class="summary-chip w">Q${i+1} ‚úó</span>`;
    }
  });

  const area = document.getElementById('scoreArea');
  area.style.display = 'block';
  area.innerHTML = `
    <div class="score-card ${cls}">
      <div class="score-emoji">${emoji}</div>
      <div class="score-number">${score} / ${total}</div>
      <div class="score-pct">${pct}%</div>
      <div class="score-msg">${msg}</div>
    </div>
    <div class="summary-row">${chips}</div>
    <div style="text-align:center;">
      <button class="btn-secondary" onclick="retakeQuiz()">üîÑ Retake Quiz</button>
    </div>
  `;

  // Update progress bar to show score color
  const bar = document.getElementById('progressBar');
  bar.style.width = '100%';
  if (pct >= 80) bar.style.background = 'var(--correct)';
  else if (pct >= 60) bar.style.background = 'var(--warn)';
  else bar.style.background = 'var(--wrong)';
  document.getElementById('progressText').textContent = `Score: ${score} / ${total} (${pct}%)`;
}

// ============================================================
// RETAKE
// ============================================================
function retakeQuiz() {
  answers = new Array(QUESTIONS.length).fill(null);
  submitted = false;

  document.getElementById('scoreArea').style.display = 'none';
  document.getElementById('submitArea').style.display = 'block';
  document.getElementById('progressBar').style.background = 'var(--accent)';

  renderQuestions();
  updateProgress();
  window.scrollTo({ top: 0, behavior: 'smooth' });
}

// ============================================================
// INIT
// ============================================================
renderQuestions();
updateProgress();
</script>
</body>
</html>
