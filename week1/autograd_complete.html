<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Lesson 2: Autograd ‚Äî Complete Interactive Walkthrough</title>
<link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@400;500;600;700&family=Newsreader:opsz,wght@6..72,400;6..72,600;6..72,700&family=DM+Sans:wght@400;500;600;700&display=swap" rel="stylesheet">
<style>
:root {
  --bg:#fefcf8;--surface:#fff;--surface2:#f7f5ef;--surface3:#efebd8;
  --border:#e0dbc8;--border2:#d1cbb4;
  --text:#1c1a14;--text-dim:#7d7760;--text-light:#a59e86;
  --red:#d44;--red-bg:#fef0ef;--red-border:#f5c6c2;
  --blue:#2872d4;--blue-bg:#edf3fd;--blue-border:#b8d0f5;
  --green:#288a4c;--green-bg:#effaf3;--green-border:#b8e6c8;
  --gold:#b8860b;--gold-bg:#fdf8ec;--gold-border:#e8d9a0;
  --purple:#7044c4;--purple-bg:#f3effe;--purple-border:#cbb8f0;
  --orange:#c86420;
}

*{margin:0;padding:0;box-sizing:border-box;}
body{background:var(--bg);color:var(--text);font-family:'DM Sans',sans-serif;line-height:1.75;-webkit-font-smoothing:antialiased;}

.page{max-width:820px;margin:0 auto;padding:36px 20px 120px;}

/* Hero */
.hero{padding:40px 0 44px;border-bottom:2px solid var(--border);}
.hero-tag{font-family:'JetBrains Mono',monospace;font-size:.68rem;color:var(--blue);letter-spacing:2.5px;text-transform:uppercase;margin-bottom:10px;}
h1{font-family:'Newsreader',serif;font-size:2.5rem;font-weight:700;line-height:1.15;color:var(--text);margin-bottom:8px;}
.hero p{color:var(--text-dim);font-size:.95rem;max-width:560px;}

/* Progress */
.progress-bar{position:sticky;top:0;z-index:100;background:var(--bg);border-bottom:1px solid var(--border);padding:10px 0;}
.progress-inner{max-width:820px;margin:0 auto;padding:0 20px;display:flex;gap:4px;overflow-x:auto;}
.prog-dot{width:100%;height:5px;border-radius:3px;background:var(--border);transition:background .3s;flex-shrink:0;min-width:20px;}
.prog-dot.done{background:var(--green);}
.prog-dot.current{background:var(--blue);}

/* Sections */
.section{padding:44px 0;border-bottom:1px solid var(--border);}
.section:last-child{border-bottom:none;}
.sec-num{font-family:'JetBrains Mono',monospace;font-size:.7rem;color:var(--text-light);letter-spacing:1.5px;margin-bottom:4px;}
h2{font-family:'Newsreader',serif;font-size:1.55rem;font-weight:600;margin-bottom:14px;}
h3{font-family:'Newsreader',serif;font-size:1.15rem;font-weight:600;margin:24px 0 10px;color:var(--text);}
.desc{color:var(--text-dim);font-size:.92rem;margin-bottom:18px;max-width:660px;}
.desc strong{color:var(--text);}

/* Code */
.code{background:var(--text);color:#e8e4d8;border-radius:10px;padding:18px 20px;font-family:'JetBrains Mono',monospace;font-size:.8rem;line-height:1.85;overflow-x:auto;margin:14px 0;position:relative;}
.code .cm{color:#8a8470;} .code .kw{color:#c9a0ff;} .code .fn{color:#7bc8f6;}
.code .st{color:#a8d8a0;} .code .num{color:#ffd580;} .code .hl{color:#ff8080;font-weight:600;}
.code .out{color:#a8d8a0;opacity:.7;} .code .arrow{color:#ffd580;}
.code-label{position:absolute;top:8px;right:12px;font-size:.6rem;color:#8a8470;letter-spacing:1px;text-transform:uppercase;}

/* Callout boxes */
.box{border-radius:10px;padding:16px 20px;margin:16px 0;font-size:.9rem;border-left:3px solid;}
.box-analogy{background:var(--gold-bg);border-color:var(--gold);} .box-analogy strong{color:var(--gold);}
.box-key{background:var(--red-bg);border-color:var(--red);} .box-key strong{color:var(--red);}
.box-tip{background:var(--green-bg);border-color:var(--green);} .box-tip strong{color:var(--green);}
.box-info{background:var(--blue-bg);border-color:var(--blue);} .box-info strong{color:var(--blue);}

/* Card */
.card{background:var(--surface);border:1px solid var(--border);border-radius:12px;padding:22px;margin:16px 0;}

/* Canvas */
canvas{display:block;width:100%;border-radius:8px;margin:8px 0;}

/* Controls */
.ctrl{display:flex;align-items:center;gap:12px;padding:10px 14px;background:var(--surface2);border-radius:8px;margin:10px 0;}
.ctrl-lbl{font-family:'JetBrains Mono',monospace;font-size:.75rem;color:var(--text-dim);white-space:nowrap;}
.ctrl-val{font-family:'JetBrains Mono',monospace;font-size:.88rem;font-weight:600;min-width:55px;text-align:right;}
input[type="range"]{-webkit-appearance:none;flex:1;height:5px;border-radius:3px;background:var(--border);outline:none;}
input[type="range"]::-webkit-slider-thumb{-webkit-appearance:none;width:18px;height:18px;border-radius:50%;background:var(--text);cursor:grab;box-shadow:0 1px 6px rgba(0,0,0,.15);}

/* Info chips */
.chips{display:flex;gap:8px;flex-wrap:wrap;margin:12px 0;}
.chip{flex:1;min-width:100px;padding:10px 12px;background:var(--surface2);border:1px solid var(--border);border-radius:8px;}
.chip .c-lbl{font-family:'JetBrains Mono',monospace;font-size:.6rem;text-transform:uppercase;letter-spacing:.7px;color:var(--text-light);margin-bottom:1px;}
.chip .c-val{font-family:'JetBrains Mono',monospace;font-size:1rem;font-weight:600;}
.c-red{color:var(--red);} .c-blue{color:var(--blue);} .c-green{color:var(--green);} .c-gold{color:var(--gold);} .c-purple{color:var(--purple);}

/* Buttons */
.btn{font-family:'JetBrains Mono',monospace;font-size:.76rem;padding:8px 18px;border-radius:7px;cursor:pointer;transition:all .15s;border:1.5px solid;}
.btn-fill{background:var(--text);color:var(--bg);border-color:var(--text);}
.btn-fill:hover{opacity:.85;}
.btn-out{background:var(--surface);color:var(--text);border-color:var(--border);}
.btn-out:hover{border-color:var(--text);}
.btn-red{background:var(--red-bg);color:var(--red);border-color:var(--red-border);}
.btn-green{background:var(--green-bg);color:var(--green);border-color:var(--green-border);}
.btn-row{display:flex;gap:8px;flex-wrap:wrap;margin:12px 0;}

/* Flow diagram */
.flow{display:flex;align-items:center;justify-content:center;gap:6px;flex-wrap:wrap;padding:16px 0;}
.flow-node{padding:10px 16px;border-radius:8px;font-family:'JetBrains Mono',monospace;font-size:.8rem;font-weight:600;border:2px solid;text-align:center;}
.flow-arrow{color:var(--text-dim);font-size:1.1rem;}
.fn-blue{border-color:var(--blue);color:var(--blue);background:var(--blue-bg);}
.fn-purple{border-color:var(--purple);color:var(--purple);background:var(--purple-bg);}
.fn-red{border-color:var(--red);color:var(--red);background:var(--red-bg);}
.fn-green{border-color:var(--green);color:var(--green);background:var(--green-bg);}
.fn-gold{border-color:var(--gold);color:var(--gold);background:var(--gold-bg);}

/* Accum bars */
.accum-area{display:flex;align-items:flex-end;height:100px;gap:6px;padding:0 10px;border-bottom:1px solid var(--border);margin-bottom:20px;}
.a-bar{flex:1;border-radius:5px 5px 0 0;transition:height .3s;position:relative;min-height:3px;}
.a-bar .a-val{position:absolute;top:-18px;left:50%;transform:translateX(-50%);font-family:'JetBrains Mono',monospace;font-size:.7rem;font-weight:600;white-space:nowrap;}

/* Quiz */
.quiz{background:var(--surface2);border:1px solid var(--border);border-radius:12px;padding:20px;margin:20px 0;}
.quiz-q{font-weight:600;margin-bottom:12px;font-size:.92rem;}
.quiz-opts{display:flex;flex-direction:column;gap:6px;}
.quiz-opt{padding:10px 14px;border:1.5px solid var(--border);border-radius:8px;cursor:pointer;font-size:.88rem;transition:all .15s;background:var(--surface);}
.quiz-opt:hover{border-color:var(--text-dim);}
.quiz-opt.correct{border-color:var(--green);background:var(--green-bg);color:var(--green);}
.quiz-opt.wrong{border-color:var(--red);background:var(--red-bg);color:var(--red);}
.quiz-opt.disabled{pointer-events:none;opacity:.7;}
.quiz-feedback{margin-top:10px;font-size:.85rem;padding:10px 14px;border-radius:8px;display:none;}

/* Two variable GD */
.gd2-stat{font-family:'JetBrains Mono',monospace;font-size:.82rem;color:var(--text-dim);margin:4px 0;}
.gd2-stat strong{color:var(--text);}

/* NN layer visual */
.nn-layer{display:flex;align-items:center;justify-content:center;gap:20px;padding:20px 0;flex-wrap:wrap;}
.nn-box{padding:12px 16px;border-radius:8px;font-family:'JetBrains Mono',monospace;font-size:.8rem;text-align:center;border:2px solid;min-width:70px;}

@keyframes fadeUp{from{opacity:0;transform:translateY(12px);}to{opacity:1;transform:translateY(0);}}
.section{animation:fadeUp .4s ease both;}

@media(max-width:600px){
  h1{font-size:1.8rem;}.page{padding:24px 14px 80px;}.card{padding:16px 12px;}
  .flow-node{padding:7px 10px;font-size:.72rem;}.chip{min-width:80px;}
}
</style>
</head>
<body>

<div class="progress-bar"><div class="progress-inner" id="progBar"></div></div>

<div class="page">

<!-- HERO -->
<div class="hero">
  <div class="hero-tag">Lesson 2 ‚Äî Complete Walkthrough</div>
  <h1>Automatic Differentiation</h1>
  <p>Every line of code explained, with interactive demos and quizzes to make sure you actually understand it.</p>
</div>

<!-- ======= SECTION 1: THE BIG PICTURE ======= -->
<div class="section" data-section="1" id="s1">
  <div class="sec-num">PART 1 OF 10</div>
  <h2>The Big Picture: Why Any of This Matters</h2>
  
  <p class="desc">Before touching any code, let's understand the <strong>one idea</strong> that everything in this lesson builds on.</p>
  
  <div class="box box-analogy">
    <strong>üéØ The core idea:</strong> A neural network is just a math function with millions of adjustable knobs (called weights). Training means turning those knobs until the output is right. The gradient tells you <em>which way to turn each knob</em>.
  </div>

  <p class="desc">Every neural network in existence ‚Äî ChatGPT, image generators, self-driving cars ‚Äî learns with this exact loop:</p>

  <div class="flow">
    <div class="flow-node fn-blue">‚ë† Predict</div>
    <div class="flow-arrow">‚Üí</div>
    <div class="flow-node fn-red">‚ë° Measure Error</div>
    <div class="flow-arrow">‚Üí</div>
    <div class="flow-node fn-green">‚ë¢ Get Gradients</div>
    <div class="flow-arrow">‚Üí</div>
    <div class="flow-node fn-gold">‚ë£ Adjust Knobs</div>
    <div class="flow-arrow">‚Üí</div>
    <div class="flow-node fn-purple">‚ë§ Repeat</div>
  </div>

  <p class="desc">Step ‚ë¢ is the hard part. For a network with 1 million weights, you need 1 million gradients ‚Äî one for each knob. Computing these by hand is impossible. <strong>Autograd computes all of them automatically.</strong> That's this entire lesson.</p>

  <div class="quiz" id="q1">
    <div class="quiz-q">Quick check: What does a gradient tell the neural network?</div>
    <div class="quiz-opts">
      <div class="quiz-opt" data-correct="false" onclick="checkQuiz('q1',this)">How big the error is</div>
      <div class="quiz-opt" data-correct="true" onclick="checkQuiz('q1',this)">Which direction to adjust each weight to reduce error</div>
      <div class="quiz-opt" data-correct="false" onclick="checkQuiz('q1',this)">What the correct answer should be</div>
    </div>
    <div class="quiz-feedback" id="q1-fb"></div>
  </div>
</div>

<!-- ======= SECTION 2: requires_grad ======= -->
<div class="section" data-section="2" id="s2">
  <div class="sec-num">PART 2 OF 10</div>
  <h2>requires_grad=True: Turning On the Recorder</h2>

  <p class="desc">The first line of actual code in this lesson is:</p>

  <div class="code">
<span class="code-label">Python</span>
x = torch.tensor(<span class="num">3.0</span>, <span class="kw">requires_grad</span>=<span class="num">True</span>)
  </div>

  <p class="desc">This creates x = 3, but the <strong>requires_grad=True</strong> part is the magic. It tells PyTorch: <em>"from now on, record every single operation that happens to this variable."</em></p>

  <div class="box box-analogy">
    <strong>üí° Analogy:</strong> Think of it like pressing "Record" on a voice recorder before a meeting. Everything said gets captured. Later, you can play it back. Here, PyTorch records every math operation, and later "plays it back" in reverse to compute gradients.
  </div>

  <p class="desc">Without requires_grad=True, a tensor is just a number. PyTorch won't track anything ‚Äî it's like the recorder is off.</p>

  <div class="code">
<span class="cm"># No tracking ‚Äî just a plain number</span>
x = torch.tensor(<span class="num">3.0</span>)

<span class="cm"># WITH tracking ‚Äî PyTorch watches everything</span>
x = torch.tensor(<span class="num">3.0</span>, <span class="kw">requires_grad</span>=<span class="num">True</span>)
  </div>

  <div class="box box-tip">
    <strong>‚úÖ When do you use it?</strong> Only on things you want to learn/optimize ‚Äî typically the model's weights and biases. You don't set it on your training data or labels.
  </div>
</div>

<!-- ======= SECTION 3: BASIC GRADIENT ======= -->
<div class="section" data-section="3" id="s3">
  <div class="sec-num">PART 3 OF 10</div>
  <h2>Computing Your First Gradient: y = x¬≤</h2>

  <p class="desc">Now the full example. We compute y = x¬≤, then ask PyTorch for the gradient dy/dx.</p>

  <div class="code">
x = torch.tensor(<span class="num">3.0</span>, <span class="kw">requires_grad</span>=<span class="num">True</span>)  <span class="cm"># Step 1: create x, turn on recording</span>
y = x ** <span class="num">2</span>                                     <span class="cm"># Step 2: compute y = 9 (recorded!)</span>
y.<span class="fn">backward</span>()                                   <span class="cm"># Step 3: compute gradient</span>
<span class="fn">print</span>(x.grad)                                   <span class="cm"># Step 4: read the answer ‚Üí 6.0</span>
  </div>

  <p class="desc">Let's break down what happens at each step:</p>

  <div class="card">
    <h3>Step 1: x = torch.tensor(3.0, requires_grad=True)</h3>
    <p class="desc">Creates x with value 3. The recorder is ON.</p>

    <h3>Step 2: y = x ** 2</h3>
    <p class="desc">Computes y = 9. But behind the scenes, PyTorch also writes in its notebook: <em>"y was made by squaring x."</em></p>

    <h3>Step 3: y.backward()</h3>
    <p class="desc">This is where PyTorch goes backward. It knows y = x¬≤, so dy/dx = 2x. It plugs in x = 3 ‚Üí gradient = 6. This gets stored in <strong>x.grad</strong>.</p>

    <h3>Step 4: x.grad</h3>
    <p class="desc">You read the result: <strong>tensor(6.)</strong>. Done!</p>
  </div>

  <p class="desc"><strong>Try it yourself</strong> ‚Äî drag the slider to see what the gradient is at different x values:</p>

  <div class="card">
    <canvas id="basicCanvas" height="260"></canvas>
    <div class="ctrl">
      <span class="ctrl-lbl">x =</span>
      <input type="range" id="basicSlider" min="-4" max="4" step="0.1" value="3">
      <span class="ctrl-val c-blue" id="basicXV">3.0</span>
    </div>
    <div class="chips">
      <div class="chip"><div class="c-lbl">x</div><div class="c-val c-blue" id="bX">3.0</div></div>
      <div class="chip"><div class="c-lbl">y = x¬≤</div><div class="c-val c-red" id="bY">9.0</div></div>
      <div class="chip"><div class="c-lbl">x.grad (= 2x)</div><div class="c-val c-green" id="bG">6.0</div></div>
      <div class="chip"><div class="c-lbl">meaning</div><div class="c-val" id="bM" style="font-size:.78rem;color:var(--text-dim)">nudge x up ‚Üí y goes up √ó6</div></div>
    </div>
  </div>

  <div class="box box-info">
    <strong>üìñ What does the gradient actually mean?</strong> A gradient of 6 means: "if you increase x by 0.001, y will increase by about 0.006." It's the <em>sensitivity</em> of y to changes in x. At x = 0, the gradient is 0 ‚Äî the curve is flat, so nudging x barely changes y.
  </div>

  <div class="quiz" id="q2">
    <div class="quiz-q">If x = -4 and y = x¬≤, what is x.grad?</div>
    <div class="quiz-opts">
      <div class="quiz-opt" data-correct="false" onclick="checkQuiz('q2',this)">16 (because y = 16)</div>
      <div class="quiz-opt" data-correct="true" onclick="checkQuiz('q2',this)">-8 (because gradient = 2x = 2√ó(-4) = -8)</div>
      <div class="quiz-opt" data-correct="false" onclick="checkQuiz('q2',this)">4 (because x = -4 and gradient is absolute)</div>
    </div>
    <div class="quiz-feedback" id="q2-fb"></div>
  </div>
</div>

<!-- ======= SECTION 4: COMPUTATIONAL GRAPH ======= -->
<div class="section" data-section="4" id="s4">
  <div class="sec-num">PART 4 OF 10</div>
  <h2>The Computational Graph: PyTorch's Secret Notebook</h2>

  <p class="desc">The previous example had one operation. Real networks have hundreds. PyTorch handles this by building a <strong>computational graph</strong> ‚Äî a map of every operation in order.</p>

  <p class="desc">Here's a more complex example: <strong>z = 3(x + 2)¬≤</strong> at x = 2.</p>

  <div class="code">
x = torch.tensor(<span class="num">2.0</span>, <span class="kw">requires_grad</span>=<span class="num">True</span>)
a = x + <span class="num">2</span>       <span class="cm"># a = 4</span>
b = a ** <span class="num">2</span>      <span class="cm"># b = 16</span>
z = b * <span class="num">3</span>       <span class="cm"># z = 48</span>
z.<span class="fn">backward</span>()
<span class="fn">print</span>(x.grad)   <span class="cm"># ‚Üí 24.0</span>
  </div>

  <p class="desc">PyTorch builds this graph silently. Forward goes left-to-right, backward goes right-to-left:</p>

  <div class="card">
    <canvas id="compCanvas" height="220"></canvas>
  </div>

  <p class="desc">The forward pass computes the values (2 ‚Üí 4 ‚Üí 16 ‚Üí 48). The backward pass computes derivatives by multiplying along the chain ‚Äî this is called the <strong>chain rule</strong>.</p>
</div>

<!-- ======= SECTION 5: CHAIN RULE ======= -->
<div class="section" data-section="5" id="s5">
  <div class="sec-num">PART 5 OF 10</div>
  <h2>The Chain Rule: How .backward() Actually Works</h2>

  <p class="desc">This is the mathematical heart of it. For z = 3(x+2)¬≤, backward multiplies <strong>local derivatives</strong> along the path:</p>

  <div class="card">
    <div class="flow" style="margin-bottom:10px;">
      <div class="flow-node fn-blue" style="font-size:.75rem">x=2</div>
      <div class="flow-arrow">‚Üí <small>+2</small></div>
      <div class="flow-node fn-purple" style="font-size:.75rem">a=4</div>
      <div class="flow-arrow">‚Üí <small>square</small></div>
      <div class="flow-node fn-purple" style="font-size:.75rem">b=16</div>
      <div class="flow-arrow">‚Üí <small>√ó3</small></div>
      <div class="flow-node fn-red" style="font-size:.75rem">z=48</div>
    </div>

    <h3>Backward pass (right to left):</h3>

    <div style="font-family:'JetBrains Mono',monospace;font-size:.88rem;line-height:2.2;padding:10px 0;">
      <div><span class="c-green">dz/db</span> = 3 &nbsp;&nbsp;&nbsp; <span style="color:var(--text-dim)">(z = b√ó3, derivative of √ó3 is just 3)</span></div>
      <div><span class="c-green">db/da</span> = 2a = 8 &nbsp;&nbsp;&nbsp; <span style="color:var(--text-dim)">(b = a¬≤, derivative is 2a = 2√ó4 = 8)</span></div>
      <div><span class="c-green">da/dx</span> = 1 &nbsp;&nbsp;&nbsp; <span style="color:var(--text-dim)">(a = x+2, derivative of +2 is 1)</span></div>
      <div style="border-top:1px solid var(--border);margin-top:8px;padding-top:8px;">
        <span class="c-gold" style="font-weight:700">dz/dx</span> = 3 √ó 8 √ó 1 = <strong style="font-size:1.1rem;color:var(--gold)">24</strong>
      </div>
    </div>
  </div>

  <div class="box box-analogy">
    <strong>üí° Gear analogy:</strong> If gear A spins gear B at 1√ó speed, gear B spins gear C at 8√ó speed, and gear C spins gear D at 3√ó speed ‚Äî then gear A spins gear D at 1 √ó 8 √ó 3 = 24√ó speed. The chain rule just multiplies ratios along the chain.
  </div>

  <div class="box box-key">
    <strong>‚ö° This is ALL that .backward() does.</strong> It walks backward, multiplies local derivatives, and stores the final product in .grad. For a neural network with 1000 operations, it does 1000 of these multiplications. Automatically.
  </div>

  <div class="quiz" id="q3">
    <div class="quiz-q">For y = (x √ó 5) + 3, what is dy/dx?</div>
    <div class="quiz-opts">
      <div class="quiz-opt" data-correct="false" onclick="checkQuiz('q3',this)">3 (the constant)</div>
      <div class="quiz-opt" data-correct="true" onclick="checkQuiz('q3',this)">5 (multiply by 5 has derivative 5, adding 3 has derivative 0)</div>
      <div class="quiz-opt" data-correct="false" onclick="checkQuiz('q3',this)">8 (5 + 3)</div>
    </div>
    <div class="quiz-feedback" id="q3-fb"></div>
  </div>
</div>

<!-- ======= SECTION 6: VECTORS ======= -->
<div class="section" data-section="6" id="s6">
  <div class="sec-num">PART 6 OF 10</div>
  <h2>Gradients with Vectors</h2>

  <p class="desc">Real networks use vectors and matrices, not single numbers. When x is a vector, you get <strong>one gradient per element</strong>.</p>

  <div class="code">
x = torch.tensor([<span class="num">1.0</span>, <span class="num">2.0</span>, <span class="num">3.0</span>], <span class="kw">requires_grad</span>=<span class="num">True</span>)
y = x ** <span class="num">2</span>          <span class="cm"># [1, 4, 9]</span>
loss = y.<span class="fn">sum</span>()      <span class="cm"># 14  ‚Üê backward() needs a single number</span>
loss.<span class="fn">backward</span>()
<span class="fn">print</span>(x.grad)      <span class="cm"># tensor([2., 4., 6.])</span>
  </div>

  <div class="card">
    <canvas id="vecCanvas" height="180"></canvas>
  </div>

  <p class="desc">Each element gets its own gradient: 2√ó1=2, 2√ó2=4, 2√ó3=6. This is how a neural network knows how to adjust each individual weight differently.</p>

  <div class="box box-info">
    <strong>üìñ Why .sum() before .backward()?</strong> The backward() function needs to start from a <strong>single number</strong> (scalar). In neural networks, this number is always the <strong>loss</strong> ‚Äî one number that measures total error. You can't call backward() on a vector.
  </div>
</div>

<!-- ======= SECTION 7: ACCUMULATION ======= -->
<div class="section" data-section="7" id="s7">
  <div class="sec-num">PART 7 OF 10</div>
  <h2>‚ö†Ô∏è Gradients Accumulate! (The #1 Beginner Bug)</h2>

  <p class="desc">This trips up <strong>everyone</strong>. When you call .backward() multiple times, PyTorch <em>adds</em> the new gradient to the old one instead of replacing it.</p>

  <div class="code">
x = torch.tensor(<span class="num">2.0</span>, <span class="kw">requires_grad</span>=<span class="num">True</span>)

y = x ** <span class="num">2</span>
y.<span class="fn">backward</span>()
<span class="fn">print</span>(x.grad)      <span class="cm"># 4.0 ‚Üê correct (2√ó2=4)</span>

y = x ** <span class="num">2</span>
y.<span class="fn">backward</span>()
<span class="fn">print</span>(x.grad)      <span class="cm"># 8.0 ‚Üê WRONG! It added 4+4=8</span>

x.grad.<span class="fn">zero_</span>()     <span class="cm"># Reset to zero</span>
y = x ** <span class="num">2</span>
y.<span class="fn">backward</span>()
<span class="fn">print</span>(x.grad)      <span class="cm"># 4.0 ‚Üê correct again</span>
  </div>

  <p class="desc"><strong>Try it yourself:</strong> click backward() and watch the gradient pile up. Then click zero_() to reset.</p>

  <div class="card">
    <div class="accum-area" id="accumArea"></div>
    <div class="btn-row">
      <button class="btn btn-fill" id="accumBack">.backward() ‚Äî adds +4</button>
      <button class="btn btn-red" id="accumZero">.zero_() ‚Äî reset</button>
    </div>
    <div style="margin-top:10px;font-family:'JetBrains Mono',monospace;font-size:.88rem;">
      x.grad = <strong id="accumVal">0</strong> &nbsp;&nbsp; (backward called <strong id="accumCnt">0</strong> times)
    </div>
  </div>

  <div class="box box-key">
    <strong>‚ö° The fix:</strong> Always call <code style="background:var(--surface);padding:2px 6px;border-radius:3px;">optimizer.zero_grad()</code> at the start of each training step. This is so important that every training loop ever written includes it:
  </div>

  <div class="code">
<span class="kw">for</span> epoch <span class="kw">in</span> range(epochs):
    optimizer.<span class="fn">zero_grad</span>()    <span class="cm"># ‚Üê ALWAYS do this first</span>
    output = model(data)
    loss = criterion(output, target)
    loss.<span class="fn">backward</span>()
    optimizer.<span class="fn">step</span>()
  </div>

  <div class="quiz" id="q4">
    <div class="quiz-q">You call .backward() 5 times without zeroing gradients. If the true gradient is 4, what does x.grad show?</div>
    <div class="quiz-opts">
      <div class="quiz-opt" data-correct="false" onclick="checkQuiz('q4',this)">4 (it only keeps the latest)</div>
      <div class="quiz-opt" data-correct="true" onclick="checkQuiz('q4',this)">20 (4+4+4+4+4 ‚Äî it accumulates)</div>
      <div class="quiz-opt" data-correct="false" onclick="checkQuiz('q4',this)">Error (you can't call backward twice)</div>
    </div>
    <div class="quiz-feedback" id="q4-fb"></div>
  </div>
</div>

<!-- ======= SECTION 8: NO_GRAD ======= -->
<div class="section" data-section="8" id="s8">
  <div class="sec-num">PART 8 OF 10</div>
  <h2>torch.no_grad(): Turning Off the Recorder</h2>

  <p class="desc">Recording operations costs memory and time. During <strong>evaluation</strong> (testing your model), you don't need gradients. So you turn tracking off.</p>

  <div class="code">
<span class="cm"># TRAINING ‚Äî recorder ON (need gradients to learn)</span>
y = model(data)
loss.<span class="fn">backward</span>()     <span class="cm"># ‚úì works fine</span>

<span class="cm"># EVALUATION ‚Äî recorder OFF (just checking performance)</span>
<span class="kw">with</span> torch.<span class="fn">no_grad</span>():
    y = model(test_data)   <span class="cm"># faster, less memory</span>
  </div>

  <div class="box box-analogy">
    <strong>üí° Analogy:</strong> It's like a security camera. During training, the camera is ON ‚Äî recording everything so you can review (backpropagate). During testing, turn the camera OFF ‚Äî you're just watching the live feed, not recording. Saves disk space (memory) and runs faster.
  </div>

  <p class="desc">There's also <strong>.detach()</strong> for individual tensors:</p>

  <div class="code">
y = x ** <span class="num">2</span>            <span class="cm"># y tracks gradients</span>
z = y.<span class="fn">detach</span>()         <span class="cm"># z has same value as y, but NO tracking</span>
  </div>

  <div class="box box-tip">
    <strong>‚úÖ Rule of thumb:</strong> Use <code>torch.no_grad()</code> in evaluation functions. Use <code>.detach()</code> when you need to "break the chain" ‚Äî take a value out of the graph without stopping everything.
  </div>
</div>

<!-- ======= SECTION 9: GRADIENT DESCENT ======= -->
<div class="section" data-section="9" id="s9">
  <div class="sec-num">PART 9 OF 10</div>
  <h2>Gradient Descent: Everything Working Together</h2>

  <p class="desc">Now the payoff. We combine everything to find the minimum of f(x) = (x ‚àí 3)¬≤. The answer is x = 3 (where the error is 0), but we start at x = 10 and let gradient descent find it.</p>

  <div class="code">
x = torch.tensor(<span class="num">10.0</span>, <span class="kw">requires_grad</span>=<span class="num">True</span>)
learning_rate = <span class="num">0.1</span>

<span class="kw">for</span> step <span class="kw">in</span> range(<span class="num">20</span>):
    f = (x - <span class="num">3</span>) ** <span class="num">2</span>          <span class="cm"># ‚ë† Forward: compute loss</span>
    f.<span class="fn">backward</span>()               <span class="cm"># ‚ë° Backward: get gradient</span>
    <span class="kw">with</span> torch.<span class="fn">no_grad</span>():
        x -= learning_rate * x.grad  <span class="cm"># ‚ë¢ Update: step downhill</span>
    x.grad.<span class="fn">zero_</span>()             <span class="cm"># ‚ë£ Zero: reset for next round</span>
  </div>

  <p class="desc">Each iteration does the full cycle: forward ‚Üí backward ‚Üí update ‚Üí zero. Watch the ball roll downhill:</p>

  <div class="card">
    <canvas id="gdCanvas" height="280"></canvas>
    <div class="btn-row">
      <button class="btn btn-fill" id="gdStep">Take 1 step</button>
      <button class="btn btn-out" id="gdAuto">Auto-run</button>
      <button class="btn btn-red" id="gdReset">Reset</button>
    </div>
    <div class="ctrl">
      <span class="ctrl-lbl">learning rate</span>
      <input type="range" id="lrSlider" min="0.01" max="0.5" step="0.01" value="0.1">
      <span class="ctrl-val c-gold" id="lrVal">0.10</span>
    </div>
    <div class="chips">
      <div class="chip"><div class="c-lbl">step</div><div class="c-val" id="gdSN">0</div></div>
      <div class="chip"><div class="c-lbl">x</div><div class="c-val c-blue" id="gdXV">10.000</div></div>
      <div class="chip"><div class="c-lbl">f(x) = loss</div><div class="c-val c-red" id="gdFV">49.000</div></div>
      <div class="chip"><div class="c-lbl">gradient</div><div class="c-val c-green" id="gdGV">14.000</div></div>
    </div>
  </div>

  <div class="box box-info">
    <strong>üìñ Try the learning rate slider!</strong> At 0.01 it crawls. At 0.5 it overshoots and bounces. Around 0.1 is the sweet spot. Real neural network training has the exact same tradeoff ‚Äî finding the right learning rate is one of the most important decisions.
  </div>

  <div class="box box-key">
    <strong>‚ö° These 4 lines are the engine of ALL deep learning.</strong> Everything else ‚Äî fancy architectures, GPUs, billion-parameter models ‚Äî runs on this loop: forward ‚Üí backward ‚Üí update ‚Üí zero.
  </div>
</div>

<!-- ======= SECTION 10: NEURAL NETWORK PREVIEW ======= -->
<div class="section" data-section="10" id="s10">
  <div class="sec-num">PART 10 OF 10</div>
  <h2>Preview: How This Connects to Neural Networks</h2>

  <p class="desc">In the lesson code, the final example shows a simple neural network layer: <strong>y = Wx + b</strong>. This is exactly the same concept, but with matrices instead of single numbers.</p>

  <div class="code">
W = torch.randn(<span class="num">3</span>, <span class="num">2</span>, <span class="kw">requires_grad</span>=<span class="num">True</span>)  <span class="cm"># 6 weights (3√ó2 matrix)</span>
b = torch.randn(<span class="num">3</span>, <span class="kw">requires_grad</span>=<span class="num">True</span>)     <span class="cm"># 3 biases</span>
x = torch.randn(<span class="num">2</span>)                          <span class="cm"># input (2 features)</span>

y = W @ x + b          <span class="cm"># Forward: matrix multiply + bias</span>
loss = y.<span class="fn">sum</span>()         <span class="cm"># Compute loss</span>
loss.<span class="fn">backward</span>()        <span class="cm"># Backward: get ALL gradients at once</span>

<span class="cm"># Now W.grad has 6 values and b.grad has 3 values</span>
<span class="cm"># Each tells PyTorch how to adjust that specific weight</span>
  </div>

  <div class="nn-layer">
    <div class="nn-box fn-blue" style="font-size:.75rem">Input<br>x (2)</div>
    <div class="flow-arrow" style="font-size:1.4rem">‚Üí</div>
    <div class="nn-box fn-purple" style="font-size:.75rem">Weights<br>W (3√ó2)<br>+ bias b (3)</div>
    <div class="flow-arrow" style="font-size:1.4rem">‚Üí</div>
    <div class="nn-box fn-red" style="font-size:.75rem">Output<br>y (3)</div>
    <div class="flow-arrow" style="font-size:1.4rem">‚Üí</div>
    <div class="nn-box fn-gold" style="font-size:.75rem">Loss<br>(1 number)</div>
  </div>

  <p class="desc">The key insight: <strong>calling loss.backward() computes gradients for W AND b simultaneously</strong>. W.grad tells you how to adjust each of the 6 weights, and b.grad tells you how to adjust each of the 3 biases. Scale this to millions of weights and you have modern deep learning.</p>

  <h3>Complete Summary</h3>

  <div style="display:grid;grid-template-columns:repeat(auto-fill,minmax(220px,1fr));gap:10px;margin:16px 0;">
    <div class="chip"><div class="c-lbl">requires_grad=True</div><div class="c-val" style="font-size:.78rem;color:var(--blue)">Turn on the recorder</div></div>
    <div class="chip"><div class="c-lbl">.backward()</div><div class="c-val" style="font-size:.78rem;color:var(--red)">Walk backward, compute gradients</div></div>
    <div class="chip"><div class="c-lbl">.grad</div><div class="c-val" style="font-size:.78rem;color:var(--green)">Read the computed gradient</div></div>
    <div class="chip"><div class="c-lbl">.zero_()</div><div class="c-val" style="font-size:.78rem;color:var(--gold)">Reset before next iteration</div></div>
    <div class="chip"><div class="c-lbl">torch.no_grad()</div><div class="c-val" style="font-size:.78rem;color:var(--purple)">Turn off during evaluation</div></div>
    <div class="chip"><div class="c-lbl">x -= lr √ó grad</div><div class="c-val" style="font-size:.78rem;color:var(--orange)">The update rule</div></div>
  </div>

  <div class="quiz" id="q5">
    <div class="quiz-q">Final quiz: Put these in the correct training loop order.</div>
    <div class="quiz-opts">
      <div class="quiz-opt" data-correct="false" onclick="checkQuiz('q5',this)">backward ‚Üí forward ‚Üí zero_grad ‚Üí step</div>
      <div class="quiz-opt" data-correct="false" onclick="checkQuiz('q5',this)">forward ‚Üí step ‚Üí backward ‚Üí zero_grad</div>
      <div class="quiz-opt" data-correct="true" onclick="checkQuiz('q5',this)">zero_grad ‚Üí forward ‚Üí backward ‚Üí step</div>
    </div>
    <div class="quiz-feedback" id="q5-fb"></div>
  </div>
</div>

</div><!-- /page -->

<script>
// ====== UTILS ======
function setupCanvas(c){const d=window.devicePixelRatio||1,r=c.getBoundingClientRect();c.width=r.width*d;c.height=r.height*d;const x=c.getContext('2d');x.scale(d,d);return{x,w:r.width,h:r.height};}

// ====== PROGRESS BAR ======
const sections=document.querySelectorAll('.section');
const progBar=document.getElementById('progBar');
sections.forEach((_,i)=>{const d=document.createElement('div');d.className='prog-dot';progBar.appendChild(d);});
const progDots=progBar.querySelectorAll('.prog-dot');

function updateProgress(){
  const scrollY=window.scrollY+window.innerHeight*0.4;
  let current=0;
  sections.forEach((s,i)=>{if(s.offsetTop<=scrollY)current=i;});
  progDots.forEach((d,i)=>{d.className='prog-dot'+(i<current?' done':i===current?' current':'');});
}
window.addEventListener('scroll',updateProgress);
updateProgress();

// ====== QUIZ ======
function checkQuiz(qid,el){
  const opts=document.querySelectorAll(`#${qid} .quiz-opt`);
  const fb=document.getElementById(`${qid}-fb`);
  const correct=el.dataset.correct==='true';
  opts.forEach(o=>o.classList.add('disabled'));
  if(correct){el.classList.add('correct');fb.style.display='block';fb.style.background='var(--green-bg)';fb.style.color='var(--green)';fb.textContent='‚úÖ Correct!';}
  else{el.classList.add('wrong');fb.style.display='block';fb.style.background='var(--red-bg)';fb.style.color='var(--red)';
    const right=document.querySelector(`#${qid} .quiz-opt[data-correct="true"]`);right.classList.add('correct');
    fb.textContent='Not quite ‚Äî the correct answer is highlighted.';}
}

// ====== SECTION 3: Basic gradient ======
const bCanvas=document.getElementById('basicCanvas');
const bSlider=document.getElementById('basicSlider');
function drawBasic(xv){
  const{x:cx,w,h}=setupCanvas(bCanvas);
  const xMn=-4.5,xMx=4.5,yMn=-1,yMx=18;
  const sx=x=>((x-xMn)/(xMx-xMn))*w, sy=y=>h-((y-yMn)/(yMx-yMn))*h;

  cx.clearRect(0,0,w,h);
  // Grid
  cx.strokeStyle='#ece9e2';cx.lineWidth=1;
  for(let g=-4;g<=4;g++){cx.beginPath();cx.moveTo(sx(g),0);cx.lineTo(sx(g),h);cx.stroke();}
  for(let g=0;g<=16;g+=4){cx.beginPath();cx.moveTo(0,sy(g));cx.lineTo(w,sy(g));cx.stroke();}
  // Axes
  cx.strokeStyle='#d1cbb4';cx.lineWidth=1.5;
  cx.beginPath();cx.moveTo(sx(0),0);cx.lineTo(sx(0),h);cx.stroke();
  cx.beginPath();cx.moveTo(0,sy(0));cx.lineTo(w,sy(0));cx.stroke();
  // Labels
  cx.fillStyle='#a59e86';cx.font='10px JetBrains Mono,monospace';cx.textAlign='center';
  for(let g=-4;g<=4;g++){if(g!==0)cx.fillText(g,sx(g),sy(0)+14);}
  // Curve
  cx.strokeStyle='#d44';cx.lineWidth=2.5;cx.beginPath();
  for(let p=0;p<=w;p++){const x=xMn+(p/w)*(xMx-xMn);const y=x*x;if(p===0)cx.moveTo(p,sy(y));else cx.lineTo(p,sy(y));}
  cx.stroke();
  cx.fillStyle='#d44';cx.font='600 11px JetBrains Mono,monospace';cx.textAlign='left';cx.fillText('y = x¬≤',sx(2.8),sy(10));

  const yv=xv*xv,gv=2*xv,px=sx(xv),py=sy(yv);
  // Tangent
  const tl=1.5;cx.strokeStyle='#2872d4';cx.lineWidth=2;cx.setLineDash([5,4]);
  cx.beginPath();cx.moveTo(sx(xv-tl),sy(yv-gv*tl));cx.lineTo(sx(xv+tl),sy(yv+gv*tl));cx.stroke();cx.setLineDash([]);
  // Dashed
  cx.strokeStyle='#d1cbb4';cx.lineWidth=1;cx.setLineDash([3,3]);
  cx.beginPath();cx.moveTo(px,py);cx.lineTo(px,sy(0));cx.stroke();
  cx.beginPath();cx.moveTo(px,py);cx.lineTo(sx(0),py);cx.stroke();cx.setLineDash([]);
  // Dot
  cx.fillStyle='#1c1a14';cx.beginPath();cx.arc(px,py,6,0,Math.PI*2);cx.fill();
  cx.fillStyle='#fff';cx.beginPath();cx.arc(px,py,2.5,0,Math.PI*2);cx.fill();

  document.getElementById('basicXV').textContent=xv.toFixed(1);
  document.getElementById('bX').textContent=xv.toFixed(1);
  document.getElementById('bY').textContent=yv.toFixed(1);
  document.getElementById('bG').textContent=gv.toFixed(1);
  const m=Math.abs(gv)<0.3?'flat ‚Äî minimum':gv>0?`nudge x up ‚Üí y goes up √ó${Math.abs(gv).toFixed(0)}`:`nudge x up ‚Üí y goes down √ó${Math.abs(gv).toFixed(0)}`;
  document.getElementById('bM').textContent=m;
}
bSlider.addEventListener('input',()=>drawBasic(parseFloat(bSlider.value)));
drawBasic(3);

// ====== SECTION 4: Comp graph ======
const compCanvas=document.getElementById('compCanvas');
function drawComp(){
  const{x:cx,w,h}=setupCanvas(compCanvas);cx.clearRect(0,0,w,h);
  const cy=h*.36,by=h*.78,r=24;
  const ns=[
    {x:w*.08,y:cy,l:'x',v:'2',c:'#2872d4'},
    {x:w*.28,y:cy,l:'+2',v:'‚Üí4',c:'#7044c4'},
    {x:w*.48,y:cy,l:'¬≤',v:'‚Üí16',c:'#7044c4'},
    {x:w*.68,y:cy,l:'√ó3',v:'‚Üí48',c:'#7044c4'},
    {x:w*.88,y:cy,l:'z',v:'48',c:'#d44'},
  ];
  // Forward
  for(let i=0;i<ns.length-1;i++){cx.strokeStyle='#d1cbb4';cx.lineWidth=2;cx.beginPath();cx.moveTo(ns[i].x+r+2,cy);cx.lineTo(ns[i+1].x-r-8,cy);cx.stroke();cx.fillStyle='#d1cbb4';cx.beginPath();const t=ns[i+1].x-r-2;cx.moveTo(t,cy);cx.lineTo(t-6,cy-4);cx.lineTo(t-6,cy+4);cx.closePath();cx.fill();}
  cx.fillStyle='#a59e86';cx.font='600 9px JetBrains Mono,monospace';cx.textAlign='center';cx.fillText('FORWARD ‚Üí',w*.48,cy-40);
  // Backward
  for(let i=ns.length-1;i>0;i--){cx.strokeStyle='#288a4c';cx.lineWidth=1.5;cx.setLineDash([4,3]);cx.beginPath();cx.moveTo(ns[i].x-r-2,by);cx.lineTo(ns[i-1].x+r+8,by);cx.stroke();cx.setLineDash([]);cx.fillStyle='#288a4c';cx.beginPath();const t=ns[i-1].x+r+2;cx.moveTo(t,by);cx.lineTo(t+6,by-4);cx.lineTo(t+6,by+4);cx.closePath();cx.fill();}
  cx.fillStyle='#288a4c';cx.font='600 9px JetBrains Mono,monospace';cx.fillText('‚Üê BACKWARD',w*.48,by+18);
  cx.font='10px JetBrains Mono,monospace';cx.fillText('√ó3',w*.78,by-9);cx.fillText('√ó2a=8',w*.58,by-9);cx.fillText('√ó1',w*.38,by-9);cx.fillText('=24',w*.16,by-9);
  // Nodes
  ns.forEach(n=>{cx.fillStyle='#fff';cx.strokeStyle=n.c;cx.lineWidth=2.5;cx.beginPath();cx.arc(n.x,cy,r,0,Math.PI*2);cx.fill();cx.stroke();cx.fillStyle=n.c;cx.font='700 13px JetBrains Mono,monospace';cx.textAlign='center';cx.fillText(n.l,n.x,cy+1);cx.fillStyle='#7d7760';cx.font='10px JetBrains Mono,monospace';cx.fillText(n.v,n.x,cy-r-7);});
}
drawComp();

// ====== SECTION 6: Vector ======
const vecCanvas=document.getElementById('vecCanvas');
function drawVec(){
  const{x:cx,w,h}=setupCanvas(vecCanvas);cx.clearRect(0,0,w,h);
  const xs=[1,2,3],ys=[1,4,9],gs=[2,4,6],lbs=['x‚ÇÅ=1','x‚ÇÇ=2','x‚ÇÉ=3'];
  const bw=Math.min(70,w/5.5),mh=h-50,mg=6;
  const st=(w-(bw*2+mg)*3)/2;
  xs.forEach((_,i)=>{
    const bx=st+i*(bw*2+mg+30);
    const yh=(ys[i]/9)*mh*.7;
    cx.fillStyle='rgba(212,68,68,0.2)';cx.fillRect(bx,h-28-yh,bw,yh);cx.fillStyle='#d44';cx.font='600 10px JetBrains Mono,monospace';cx.textAlign='center';cx.fillText('y='+ys[i],bx+bw/2,h-32-yh);
    const gh=(gs[i]/6)*mh*.7;
    cx.fillStyle='rgba(40,138,76,0.2)';cx.fillRect(bx+bw+mg,h-28-gh,bw,gh);cx.fillStyle='#288a4c';cx.fillText('grad='+gs[i],bx+bw+mg+bw/2,h-32-gh);
    cx.fillStyle='#7d7760';cx.font='11px JetBrains Mono,monospace';cx.fillText(lbs[i],bx+bw+mg/2,h-8);
  });
  cx.fillStyle='rgba(212,68,68,0.2)';cx.fillRect(12,10,10,10);cx.fillStyle='#d44';cx.font='10px JetBrains Mono,monospace';cx.textAlign='left';cx.fillText('y = x¬≤',28,19);
  cx.fillStyle='rgba(40,138,76,0.2)';cx.fillRect(12,26,10,10);cx.fillStyle='#288a4c';cx.fillText('gradient = 2x',28,35);
}
drawVec();

// ====== SECTION 7: Accumulation ======
let aGrad=0,aCnt=0,aHist=[0];
const aArea=document.getElementById('accumArea');
function renderAccum(){
  aArea.innerHTML='';const show=aHist.slice(-10);const mx=Math.max(...aHist,4);
  show.forEach((v,i)=>{const d=document.createElement('div');d.className='a-bar';d.style.height=Math.max((v/mx)*90,3)+'%';d.style.background=v===0?'var(--red)':'var(--blue)';d.style.opacity=i===show.length-1?'1':'0.35';d.innerHTML=`<span class="a-val" style="color:${v===0?'var(--red)':'var(--blue)'}">${v}</span>`;aArea.appendChild(d);});
  document.getElementById('accumVal').textContent=aGrad;document.getElementById('accumCnt').textContent=aCnt;
}
document.getElementById('accumBack').addEventListener('click',()=>{aGrad+=4;aCnt++;aHist.push(aGrad);renderAccum();});
document.getElementById('accumZero').addEventListener('click',()=>{aGrad=0;aHist.push(0);renderAccum();});
renderAccum();

// ====== SECTION 9: Gradient Descent ======
const gdC=document.getElementById('gdCanvas');const lrS=document.getElementById('lrSlider');
let gX=10,gS=0,gH=[10],gAI=null;
function drawGD(){
  const{x:cx,w,h}=setupCanvas(gdC);
  const xMn=-1,xMx=12,yMn=-3,yMx=55;
  const sx=x=>((x-xMn)/(xMx-xMn))*w, sy=y=>h-((y-yMn)/(yMx-yMn))*h;
  cx.clearRect(0,0,w,h);
  // Grid
  cx.strokeStyle='#ece9e2';cx.lineWidth=1;for(let g=0;g<=12;g+=2){cx.beginPath();cx.moveTo(sx(g),0);cx.lineTo(sx(g),h);cx.stroke();}
  cx.strokeStyle='#d1cbb4';cx.lineWidth=1.5;cx.beginPath();cx.moveTo(0,sy(0));cx.lineTo(w,sy(0));cx.stroke();
  // Curve
  cx.strokeStyle='#d44';cx.lineWidth=2.5;cx.beginPath();
  for(let p=0;p<=w;p++){const x=xMn+(p/w)*(xMx-xMn);const y=(x-3)**2;if(p===0)cx.moveTo(p,sy(y));else cx.lineTo(p,sy(y));}cx.stroke();
  cx.fillStyle='#d44';cx.font='600 11px JetBrains Mono,monospace';cx.textAlign='left';cx.fillText('f(x) = (x‚àí3)¬≤',sx(6.5),sy(22));
  // Min
  cx.fillStyle='#288a4c';cx.font='600 10px JetBrains Mono,monospace';cx.textAlign='center';cx.fillText('‚óè minimum (x=3)',sx(3),sy(0)+16);
  // Trail
  for(let i=0;i<gH.length-1;i++){const x1=gH[i],y1=(x1-3)**2,x2=gH[i+1],y2=(x2-3)**2;cx.strokeStyle='rgba(40,114,212,0.15)';cx.lineWidth=1.5;cx.setLineDash([3,3]);cx.beginPath();cx.moveTo(sx(x1),sy(y1));cx.lineTo(sx(x2),sy(y2));cx.stroke();cx.setLineDash([]);cx.fillStyle='rgba(40,114,212,0.15)';cx.beginPath();cx.arc(sx(x1),sy(y1),3,0,Math.PI*2);cx.fill();}
  // Arrow
  const fv=(gX-3)**2,gv=2*(gX-3),px=sx(gX),py=sy(fv);
  if(Math.abs(gv)>0.05){const d=-Math.sign(gv);const l=Math.min(Math.abs(gv)*5,60);cx.strokeStyle='#288a4c';cx.lineWidth=2.5;cx.beginPath();cx.moveTo(px,py);cx.lineTo(px+d*l,py);cx.stroke();cx.fillStyle='#288a4c';cx.beginPath();const t=px+d*l;cx.moveTo(t+d*7,py);cx.lineTo(t,py-5);cx.lineTo(t,py+5);cx.closePath();cx.fill();}
  // Ball
  cx.fillStyle='#1c1a14';cx.beginPath();cx.arc(px,py,7,0,Math.PI*2);cx.fill();cx.fillStyle='#fff';cx.beginPath();cx.arc(px,py,3,0,Math.PI*2);cx.fill();
  // Stats
  document.getElementById('gdSN').textContent=gS;document.getElementById('gdXV').textContent=gX.toFixed(3);document.getElementById('gdFV').textContent=fv.toFixed(3);document.getElementById('gdGV').textContent=gv.toFixed(3);
}
function gdTake(){const lr=parseFloat(lrS.value);const gv=2*(gX-3);gX-=lr*gv;gS++;gH.push(gX);drawGD();}
document.getElementById('gdStep').addEventListener('click',gdTake);
document.getElementById('gdAuto').addEventListener('click',function(){
  if(gAI){clearInterval(gAI);gAI=null;this.textContent='Auto-run';return;}
  this.textContent='Pause';gAI=setInterval(()=>{if(Math.abs(gX-3)<0.001||gS>60){clearInterval(gAI);gAI=null;document.getElementById('gdAuto').textContent='Auto-run';return;}gdTake();},250);
});
document.getElementById('gdReset').addEventListener('click',()=>{clearInterval(gAI);gAI=null;document.getElementById('gdAuto').textContent='Auto-run';gX=10;gS=0;gH=[10];drawGD();});
lrS.addEventListener('input',()=>{document.getElementById('lrVal').textContent=parseFloat(lrS.value).toFixed(2);});
drawGD();

// Resize
window.addEventListener('resize',()=>{drawBasic(parseFloat(bSlider.value));drawComp();drawVec();drawGD();});
</script>
</body>
</html>
